import os
import numpy as np
from matplotlib import pyplot as plt
from torch.utils.data import DataLoader, Dataset
import torch

import scipy.sparse as sp

from transformers import AutoTokenizer, AutoModel

import scanpy as sc



# =========================
# å·¥å…·å‡½æ•°ï¼ˆä¿æŒï¼‰
# =========================
def np_norm(inp):
    max_in = np.max(inp)
    min_in = np.min(inp)
    return (inp - min_in) / (max_in - min_in + 1e-8)


def gray_value_of_gene(gene_class, gene_order):
    gene_order = list(gene_order)
    Index = gene_order.index(gene_class)
    interval = 255 / len(gene_order)
    value = Index * interval
    return int(value)


# =========================
# é¡¶å±‚å…¥å£ï¼ˆä¿æŒæ¥å£ä¸å˜ï¼‰
# =========================
def load_data(data_root, dataset_use, status, SR_times, gene_num, all_gene,
              gene_order=None, gene_name_order=None, pre_model_dir=None):
    dataset = Data_all(
        data_root, dataset_use, SR_times, status, gene_num, all_gene,
        gene_order, gene_name_order, pre_model_dir=pre_model_dir
    )
    return dataset


class Data_all(Dataset):
    """
    å¤šç±»ï¼ˆmulti-classï¼‰å¤šå­æ•°æ®é›†è”åˆåŠ è½½ï¼š
    - æ¯ä¸ªç±»æ ¹ç›®å½•åŒ…å« coexpression_matrix.npyï¼ˆâ† ä¿®æ­£è·¯å¾„ï¼‰
    - æ¯ä¸ªç±»ä¸‹ sc/ ä»…æœ‰å”¯ä¸€ .h5ad ä½œä¸ºè¯¥ç±»å…±äº« sc å‚è€ƒ
    - ç±»å†…å¤šä¸ªå­æ•°æ®é›†å…±äº« scï¼›å­æ•°æ®é›†æŒ‰ gene_order.npy / gene_name.txt æˆªå–å‰ self.gene_num åŸºå› 
    - __getitem__ æŒ‰ patch æ‰€å±ç±»åŠ¨æ€é€‰æ‹©å¯¹åº”çš„ coexpression çŸ©é˜µ
    """

    _ALL_CLASSES = [
        'Human_breast_cancer',
        'Human_colon_cancer',
        'Human_healthy_kidney',
        'Human_kidney_cancer',
        'Mouse_healthy_brain'
    ]

    def __init__(self, data_root, dataset_use, SR_times, status, gene_num,
                 all_gene, gene_order, gene_name_order, pre_model_dir):
        self.data_root = data_root
        self.status = status
        self.gene_num = int(gene_num) if gene_num is not None else 20
        self.selected_classes = self._ALL_CLASSES

        # ---- æ‰«ææ‰€æœ‰ç±»ä¸‹çš„ patch ä¿¡æ¯ï¼Œè®°å½•æ‰€å±ç±»
        self.selected_patches = []
        for cls_name in self.selected_classes:
            print(f"ğŸ”¹ Scanning class: {cls_name}")
            cls_patches = self._load_patch_list(self.data_root, cls_name)
            # (cls_name, sub, layer_name, patch_id)
            self.selected_patches.extend([(cls_name, *p) for p in cls_patches])

        if status == 'Test':
            self._sort_patches()

        # ---- æ¯ç±»åŠ è½½ sc.h5adï¼ˆä»…ä¸€ä¸ªï¼‰
        self.sc_reference = {}
        for cls_name in self.selected_classes:
            self.sc_reference[cls_name] = self._load_sc_reference(cls_name)

        # ---- æ¯å­æ•°æ®é›†çš„ gene_order.npy / gene_name.txtï¼ˆæˆªå–å‰ self.gene_numï¼‰
        self.sub_gene_info = self._load_subdataset_gene_info()

        # ---- åŠ è½½æ¯ç±»å…±è¡¨è¾¾çŸ©é˜µï¼ˆä¿®æ­£è·¯å¾„ï¼š<root>/<cls>/coexpression_matrix.npyï¼‰
        self._load_coexpression(self.data_root)

        # ---- åŠ è½½ ST / spot / WSI / mask / sc ç´¢å¼•
        self._load_data(self.data_root)

        # ---- å½’ä¸€åŒ–
        self._normalize_data()

        # ---- BERT å…ƒæ•°æ®
        self._load_bert_model(pre_model_dir)
        self._embed_metadata()

        # ---- gene index mapsï¼ˆä¿æŒï¼‰
        self._precompute_gene_index_maps()

        print(f"[{status}] Loaded {len(self.selected_patches)} patches from {len(self.selected_classes)} classes.")

    # ===================================================== #
    # Patch æ‰«æ
    # ç›®å½•ç»“æ„ï¼ˆç¤ºä¾‹ï¼‰ï¼š
    # <root>/<cls>/<sub>/HR_ST/extract/<layer>/<patch_id>/HR_ST_256.npz
    # ===================================================== #
    def _load_patch_list(self, data_root, cls_name):
        patches = []
        root = os.path.join(data_root, cls_name)
        if not os.path.isdir(root):
            print(f"âš ï¸ Missing class dir: {root}")
            return patches

        for sub in sorted(os.listdir(root)):
            sub_path = os.path.join(root, sub)
            if not os.path.isdir(sub_path) or sub == 'sc':
                continue
            extract_base = os.path.join(sub_path, 'HR_ST', 'extract')
            if not os.path.isdir(extract_base):
                continue
            for layer_name in sorted(os.listdir(extract_base)):
                layer_dir = os.path.join(extract_base, layer_name)
                if not os.path.isdir(layer_dir):
                    continue
                for patch_id in sorted(os.listdir(layer_dir)):
                    patches.append((sub, layer_name, patch_id))
        return patches

    def _sort_patches(self):
        # selected_patches: (cls_name, sub, layer, patch_id)
        # è¿™é‡ŒæŒ‰ (cls, sub, layer, patch_id) å­—å…¸åºæ’åºï¼Œæˆ–å¯æŒ‰ patch_id è‡ªå®šä¹‰è§„åˆ™
        self.selected_patches.sort(key=lambda x: (x[0], x[1], x[2], x[3]))

    # ===================================================== #
    # è¯»å–æ¯ç±» sc æ–‡ä»¶ï¼ˆä»…ä¸€ä¸ª .h5adï¼›ä¿ç•™å‰1000åŸºå› ï¼‰
    # ===================================================== #
    def _load_sc_reference(self, cls_name):
        sc_dir = os.path.join(self.data_root, cls_name, 'sc')
        if not os.path.isdir(sc_dir):
            print(f"âš ï¸ Missing sc dir for {cls_name}: {sc_dir}")
            return None

        h5_list = [f for f in os.listdir(sc_dir) if f.endswith('.h5ad')]
        if len(h5_list) != 1:
            raise RuntimeError(f"{cls_name}/sc å¿…é¡»ä¸”ä»…åŒ…å«ä¸€ä¸ª .h5ad æ–‡ä»¶ï¼Œå½“å‰: {h5_list}")

        h5_path = os.path.join(sc_dir, h5_list[0])
        print(f"ğŸ”¹ Loading scRNA data for {cls_name}: {h5_path}")

        adata = sc.read_h5ad(h5_path)
        adata.var_names = adata.var_names.astype(str)
        adata.var_names_make_unique()

        # ========= 1) é™åˆ¶åŸºå› æ•°åˆ°æœ€å¤š 1000 =========
        max_genes = 100
        keep_n_genes = min(max_genes, adata.n_vars)
        adata = adata[:, adata.var_names[:keep_n_genes]].copy()

        # ========= 2) å¯é€‰ï¼šå…ˆè¿‡æ»¤æ‰å…¨ 0 ç»†èƒï¼Œæ¶ˆé™¤ warning =========
        # æœ‰ "Some cells have zero counts" çš„ warningï¼Œå¯ä»¥å…ˆå»æ‰è¿™äº›ç»†èƒ
        import numpy as np
        from scipy import sparse

        X = adata.X
        if sparse.issparse(X):
            cell_counts = np.array(X.sum(axis=1)).ravel()
        else:
            cell_counts = X.sum(axis=1)

        nonzero_mask = cell_counts > 0
        if nonzero_mask.sum() < adata.n_obs:
            adata = adata[nonzero_mask, :].copy()

        # ========= 3) å½’ä¸€åŒ– + log1p =========
        sc.pp.normalize_total(adata, inplace=True)
        sc.pp.log1p(adata)
        max_cells = 100
        if adata.n_obs > max_cells:
            rng = np.random.RandomState(0)
            keep_idx = rng.choice(adata.n_obs, size=max_cells, replace=False)
            adata = adata[keep_idx, :].copy()

        print(f"âœ… {cls_name} scRNA loaded: cells={adata.n_obs}, genes={adata.n_vars}")
        return adata

    # ===================================================== #
    # è¯»å–å­æ•°æ®é›†çš„åŸºå› ç¼–å·ä¸åç§°ï¼ˆå„å–å‰ self.gene_numï¼‰
    # ===================================================== #
    def _load_subdataset_gene_info(self):
        info = {}
        for cls_name in self.selected_classes:
            cls_root = os.path.join(self.data_root, cls_name)
            if not os.path.isdir(cls_root):
                continue
            for sub in sorted(os.listdir(cls_root)):
                sub_path = os.path.join(cls_root, sub)
                if not os.path.isdir(sub_path) or sub == 'sc':
                    continue
                order_path = os.path.join(sub_path, 'gene_order.npy')
                name_path = os.path.join(sub_path, 'gene_name.txt')
                if not (os.path.exists(order_path) and os.path.exists(name_path)):
                    print(f"âš ï¸ Missing gene files for {(cls_name, sub)}: {order_path} | {name_path}")
                    continue
                order = np.load(order_path)[:self.gene_num].astype(int)
                names = np.loadtxt(name_path, dtype=str)[:self.gene_num]
                info[(cls_name, sub)] = {"idxN": order, "namesN": names.tolist()}
        return info

    # ===================================================== #
    # åŠ è½½æ¯ç±»å…±è¡¨è¾¾çŸ©é˜µï¼ˆä¿®æ­£è·¯å¾„ï¼‰
    # <root>/<cls>/coexpression_matrix.npy
    # ===================================================== #
    def _load_coexpression(self, root):
        """
        ä»…å½“å­˜åœ¨ coexpression_matrix.npy æˆ– gene_coexpre.npy æ—¶åŠ è½½ï¼Œ
        åªå–å‰ self.gene_num * 10 ä¸ªåŸºå› ï¼Œä¸åˆ›å»º defaultã€‚
        """
        self.co_expression_dict = {}
        for cls_name in self.selected_classes:
            coex_path = os.path.join(root, cls_name, 'coexpression_matrix.npy')
            if not os.path.exists(coex_path):
                coex_path = os.path.join(root, cls_name, 'gene_coexpre.npy')
            if os.path.exists(coex_path):
                co_expression = np.load(coex_path)
                keep = min(co_expression.shape[0], self.gene_num * 10)
                self.co_expression_dict[cls_name] = np.asarray(co_expression[:keep, :keep], dtype=np.float32)

    # ===================================================== #
    # åŠ è½½ ST / spot / WSI / mask / sc
    # ===================================================== #
    def _load_data(self, root):
        sr_list, spot_list, wsi5120_list, wsi320_list, wsimask_list, sc_list = [], [], [], [], [], []
        scgpt_list, prehe_list = [], []

        for cls_name, sub, layer_name, patch_id in self.selected_patches:
            base = os.path.join(root, cls_name, sub)
            key = (cls_name, sub)
            if key not in self.sub_gene_info:
                # è‹¥è¯¥å­æ•°æ®é›†æœªæä¾›åŸºå› æ–‡ä»¶åˆ™è·³è¿‡è¯¥ patch
                print(f"âš ï¸ Skip patch without gene info: {(cls_name, sub, layer_name, patch_id)}")
                continue

            idxN = self.sub_gene_info[key]['idxN']

            paths = {
                'hr': os.path.join(base, 'HR_ST', 'extract', layer_name, patch_id, 'HR_ST_256.npz'),
                'spot': os.path.join(base, 'spot_ST', 'extract', layer_name, patch_id, 'spot_ST.npz'),
                'wsi5120': os.path.join(base, 'WSI', 'extract', layer_name, patch_id, '5120_to256.npy'),
                'wsi320': os.path.join(base, 'WSI', 'extract', layer_name, patch_id, '320_to16.npy'),
                'mask': os.path.join(base, 'WSI', 'extract', layer_name, patch_id, 'cell_mask.npy'),
            }

            if not (os.path.exists(paths['hr']) and os.path.exists(paths['spot']) and
                    os.path.exists(paths['wsi5120']) and os.path.exists(paths['wsi320']) and
                    os.path.exists(paths['mask'])):
                print(f"âš ï¸ Missing files for patch: {paths}")
                continue

            # ç¨€ç–çŸ©é˜µè¯»å–ä¸æˆªå–
            sr = sp.load_npz(paths['hr'])[:, idxN].toarray().reshape(256, 256, -1).transpose(2, 0, 1)
            spot = sp.load_npz(paths['spot'])[:, idxN].toarray().reshape(26, 26, -1).transpose(2, 0, 1)

            # å½±åƒåŠ è½½
            wsi5120 = np.load(paths['wsi5120']).transpose(2, 0, 1)
            wsi320 = np.load(paths['wsi320']).transpose(0, 3, 1, 2)
            wsimask = np.load(paths['mask']).transpose(2, 0, 1)

            sr_list.append(sr.astype(np.float32))
            spot_list.append(spot.astype(np.float32))
            wsi5120_list.append(wsi5120.astype(np.float32))
            wsi320_list.append(wsi320.astype(np.float32))
            wsimask_list.append(wsimask.astype(np.float32))

            # è®°å½•æ‰€å±ç±»çš„ sc å‚è€ƒï¼ˆç›´æ¥å­˜ adata å¼•ç”¨ï¼‰
            sc_list.append(self.sc_reference.get(cls_name, None))

            # ---------- è¯»å– scGPT ----------
            scgpt_dir = os.path.join(base, 'spot_ST', 'extract', layer_name, patch_id, 'scgpt_data')
            gene_names = self.sub_gene_info[key]['namesN']
            scgpt_embed = load_scgpt_embedding(scgpt_dir, gene_names)
            scgpt_list.append(scgpt_embed)

            # ---------- æ–°å¢ï¼šè¯»å– pre_he ----------
            pre_he_path = os.path.join(base, 'WSI', 'extract', layer_name, patch_id, 'pre_he.npy')
            pre_he = load_pre_he(pre_he_path)
            if pre_he is None:
                # ç¼ºå¤±åˆ™è¡¥é›¶çŸ©é˜µ
                print(f"âš ï¸ Missing pre_he for patch: {pre_he_path}, using zero array.")
            prehe_list.append(pre_he)
        # è½¬ä¸ºæ•°ç»„
        self.SR_ST_all = np.asarray(sr_list, dtype=np.float32)
        self.spot_ST_all = np.asarray(spot_list, dtype=np.float32)
        self.WSI_5120_all = np.asarray(wsi5120_list, dtype=np.float32)
        self.WSI_320_all = np.asarray(wsi320_list, dtype=np.float32)
        self.WSI_mask_all = np.asarray(wsimask_list, dtype=np.float32)
        self.sc_all = sc_list
        self.scgpt_list = scgpt_list
        self.prehe_list = prehe_list

        if len(self.SR_ST_all) == 0:
            print("âš ï¸ No valid patches loaded. Please check directory structure and files.")

    # ===================================================== #
    # å½’ä¸€åŒ–ï¼ˆä¿æŒï¼‰
    # ===================================================== #
    def _normalize_data(self):
        for i in range(self.spot_ST_all.shape[0]):
            data = self.spot_ST_all[i]
            mins = data.min(axis=(1, 2), keepdims=True)
            maxs = data.max(axis=(1, 2), keepdims=True)
            denom = maxs - mins + 1e-8
            self.spot_ST_all[i] = (data - mins) / denom
        patch_max = np.max(self.SR_ST_all, axis=(1, 2, 3))
        patch_max[patch_max == 0] = 1.0
        self.patch_scale = patch_max.astype(np.float32)
        self.SR_ST_all = self.SR_ST_all / patch_max[:, None, None, None]

    # ===================================================== #
    # BERT å…ƒæ•°æ®ï¼ˆä¿æŒï¼‰
    # ===================================================== #
    def _load_bert_model(self, pre_model_dir):
        self.tokenizer = AutoTokenizer.from_pretrained(f'./{pre_model_dir}/bert', trust_remote_code=True)
        self.model = AutoModel.from_pretrained(f'./{pre_model_dir}/bert', local_files_only=True, trust_remote_code=True)
        self.model.eval()

    def _embed_metadata(self):
        prompt = ("Provide spatial transcriptomics data from the Xenium5k platform "
                  "for mouse species, with a cancer condition, and brain tissue type.")
        with torch.no_grad():
            inputs = self.tokenizer(prompt, return_tensors='pt')
            outputs = self.model(**inputs)
            self.metadata_feature = outputs.pooler_output.squeeze(0)

    # ===================================================== #
    # Gene index mapsï¼ˆä¿æŒï¼‰
    # ===================================================== #
    def _precompute_gene_index_maps(self):
        N = len(self.SR_ST_all)
        self.gene_index_maps_all = np.zeros((N, self.gene_num, 256, 256), dtype=np.float32)
        for i in range(N):
            for j in range(self.gene_num):
                self.gene_index_maps_all[i, j] = np.full((256, 256), j / self.gene_num, dtype=np.float32)

    # ===================================================== #
    # Dataset æ¥å£
    # ===================================================== #
    def __len__(self):
        return len(self.SR_ST_all)

    def __getitem__(self, idx):
        """
        è¿”å›ï¼š
        - SR_ST[ C,256,256 ], spot_ST[ C,26,26 ], WSI_5120[ 3,256,256 ], WSI_320[ T,3,16,16 ]
        - gene_index_maps[ C,256,256 ], metadata_feature[768], patch_scale(float tensor)
        - coexpression_matrix[ K,K ]ï¼ˆæŒ‰æ‰€å±ç±»åŠ¨æ€é€‰æ‹©ï¼‰
        - WSI_mask[ M,256,256 ]
        - sc_item: å¯¹åº”ç±»çš„ AnnData å¼•ç”¨ï¼ˆæˆ– Noneï¼‰
        """
        # æ‰¾å›è¯¥ idx å¯¹åº”çš„ç±»å
        # æ³¨æ„ï¼šself.selected_patches å¯èƒ½æ¯” self.SR_ST_all é•¿ï¼ˆè‹¥è¿‡æ»¤äº†ç¼ºæ–‡ä»¶æ ·æœ¬ï¼‰
        # å› æ­¤æ­¤å¤„æŒ‰é¡ºåºä¸€è‡´å‡è®¾åˆ—è¡¨æœªå‘ç”Ÿä¸åŒæ­¥ï¼›å¦‚éœ€æ›´ä¸¥è°¨å¯åœ¨ _load_data ä¸­åŒæ—¶æ„å»ºä¸€ä¸ª index æ˜ å°„
        cls_name = self.selected_patches[idx][0]
        co_expression = torch.tensor(self.co_expression_dict[cls_name], dtype=torch.float32)

        patch_scale = torch.tensor(self.patch_scale[idx], dtype=torch.float32)
        sc_adata = self.sc_all[idx]          # è¿™æ˜¯ AnnData
        x = sc_adata.X                       # (n_cells, n_genes) ä¸€èˆ¬åœ¨è¿™
        if sp.issparse(x):
            x = x.toarray()
        # sc_item = np.asarray(x, dtype=np.float32)
        # å¦‚æœä½ æ›´æƒ³ç›´æ¥ tensor ä¹Ÿå¯ä»¥ï¼š
        sc_item = torch.as_tensor(x, dtype=torch.float32)

        return (
            self.SR_ST_all[idx],
            self.spot_ST_all[idx],
            self.WSI_5120_all[idx],
            self.WSI_320_all[idx],
            np.arange(self.gene_num, dtype=np.float32),
            self.gene_index_maps_all[idx],
            self.metadata_feature,
            patch_scale,
            co_expression,
            self.WSI_mask_all[idx],
            sc_item,
            self.scgpt_list[idx],
            self.prehe_list[idx]
        )

def load_scgpt_embedding(scgpt_dir, gene_names):
    """
    scgpt_dir: ç›®å½•è·¯å¾„  <patch>/spot_ST/extract/.../scgpt_data
    gene_names: list[str]  å½“å‰ gene_order å¯¹åº”çš„åå­—
    """
    G = len(gene_names)
    chunks = []

    for s in range(1, G+1, 5):   # group_size=5
        e = min(s+4, G)
        f = os.path.join(scgpt_dir, f"{s}to{e}.npy")
        if os.path.exists(f):
            chunks.append(np.load(f))
        else:
            # ç¼ºå¤±åˆ™è¡¥é›¶
            chunks.append(np.zeros_like(chunks[-1]) if chunks else None)

    # æ‹¼æ¥ä¸º (G, H, W)
    scgpt_full = np.concatenate(chunks, axis=0)
    return scgpt_full.astype(np.float32)


def load_pre_he(prehe_path):
    """
    pre_he æ˜¯ [3,256,256] çš„ embedding
    ä¸å­˜åœ¨å°±è¿”å› None
    """
    if os.path.exists(prehe_path):
        return np.load(prehe_path).astype(np.float32)
    else:
        return None
